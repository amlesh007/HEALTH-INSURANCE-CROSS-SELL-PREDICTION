{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Classification\n",
        "##### **Contribution**    - Individual\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have information about demographics (gender, age, region code type), vehicles (vehicle age, damage), policies (premium, sourcing channel), and so on to predict whether the customer would be interested in Vehicle insurance. After loading our dataset, we initially checked for null values and duplicates. There were no null values and duplicates so treatment of such was not required. Before data processing, we applied feature scaling techniques to normalize our data to bring all features on the same scale and make it easier to process ML algorithms.\n",
        "\n",
        "Next we implemented nine machine learning algorithms namely, 'LogisticRegression', 'XgbClassifier', 'RandomForestClassifier."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Our client is an Insurance company that has provided Health Insurance to its customers now they need your help in building a model to predict whether the policyholders (customers) from past year will also be interested in Vehicle Insurance provided by the company.\n",
        "\n",
        "An insurance policy is an arrangement by which a company undertakes to provide a guarantee of compensation for specified loss, damage, illness, or death in return for the payment of a specified premium. A premium is a sum of money that the customer needs to pay regularly to an insurance company for this guarantee.\n",
        "\n",
        "For example, you may pay a premium of Rs. 5000 each year for a health insurance cover of Rs. 200,000/- so that if, God forbid, you fall ill and need to be hospitalised in that year, the insurance provider company will bear the cost of hospitalisation etc. for upto Rs. 200,000. Now if you are wondering how can company bear such high hospitalisation cost when it charges a premium of only Rs. 5000/-, that is where the concept of probabilities comes in picture. For example, like you, there may be 100 customers who would be paying a premium of Rs. 5000 every year, but only a few of them (say 2-3) would get hospitalised that year and not everyone. This way everyone shares the risk of everyone else.\n",
        "\n",
        "Just like medical insurance, there is vehicle insurance where every year customer needs to pay a premium of certain amount to insurance provider company so that in case of unfortunate accident by the vehicle, the insurance provider company will provide a compensation (called ‘sum assured’) to the customer.\n",
        "\n",
        "Building a model to predict whether a customer would be interested in Vehicle Insurance is extremely helpful for the company because it can then accordingly plan its communication strategy to reach out to those customers and optimise its business model and revenue.\n",
        "\n",
        "Now, in order to predict, whether the customer would be interested in Vehicle insurance, you have information about demographics (gender, age, region code type), Vehicles (Vehicle Age, Damage), Policy (Premium, sourcing channel) etc.**"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#reading dataset\n",
        "df = pd.read_csv(r'/content/drive/MyDrive/capstone/TRAIN-HEALTH INSURANCE CROSS SELL PREDICTION.csv')\n",
        "pd.set_option('display.max_columns', None)\n"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "#Shape of data\n",
        "df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "duplicate_rows = df[df.duplicated()]\n",
        "duplicate_count = len(duplicate_rows)\n",
        "print(\"Total duplicate rows in the dataset:\", duplicate_count)\n"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "missing_counts =  df.isnull().sum()\n",
        "missing_counts"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "df.isnull().sum()\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=missing_counts.index, y=missing_counts.values)\n",
        "plt.title('Missing Values Bar Plot')\n",
        "plt.xticks(rotation=45)\n",
        "plt.xlabel('Columns')\n",
        "plt.ylabel('Missing Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. id :\tUnique ID for the customer\n",
        "\n",
        "2. Gender\t: Gender of the customer\n",
        "\n",
        "3. Age :\tAge of the customer\n",
        "\n",
        "4. Driving_License\t0 : Customer does not have DL, 1 : Customer already has DL\n",
        "\n",
        "5. Region_Code :\tUnique code for the region of the customer\n",
        "\n",
        "6. Previously_Insured\t: 1 : Customer already has Vehicle Insurance, 0 : Customer doesn't have Vehicle Insurance\n",
        "\n",
        "7. Vehicle_Age :\tAge of the Vehicle\n",
        "\n",
        "8. Vehicle_Damage\t :1 : Customer got his/her vehicle damaged in the past. 0 : Customer didn't get his/her vehicle damaged in the past.\n",
        "\n",
        "9. Annual_Premium\t: The amount customer needs to pay as premium in the year\n",
        "\n",
        "10. PolicySalesChannel :\tAnonymized Code for the channel of outreaching to the customer ie. Different Agents, Over Mail, Over Phone, In Person, etc.\n",
        "\n",
        "11. Vintage :\tNumber of Days, Customer has been associated with the company\n",
        "\n",
        "12. Response :\t1 : Customer is interested, 0 : Customer is not interested"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "df.nunique()"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "df['Gender'] = df['Gender'].map({'Female':1, 'Male':0})\n",
        "df['Vehicle_Age']= df['Vehicle_Age'].map({'< 1 Year':0,'1-2 Year':1,'> 2 Years':2})\n",
        "df['Vehicle_Damage']=df['Vehicle_Damage'].map({'Yes':1, 'No':0})"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "changing catogorical columns to numerical columns ."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "#Dependent variable 'Response'\n",
        "plt.figure(figsize=(8,7))\n",
        "sns.set_theme(style='whitegrid')\n",
        "sns.countplot(x=df['Response'],data=df)"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* From above fig we can see that the data is highly imbalanced."
      ],
      "metadata": {
        "id": "QPQKciFDWmwa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "#Distribution of Age\n",
        "plt.figure(figsize=(16,10))\n",
        "sns.countplot(x=df['Age'],data=df)"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* From the above distribution of age we can see that most of the customers age is between 21 to 25 years.There are few Customers above the age of 60 years."
      ],
      "metadata": {
        "id": "0QRFrGbGWwc0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "\n",
        "plt.figure(figsize=(7,9))\n",
        "plt.pie(df['Previously_Insured'].value_counts(), autopct='%.0f%%', shadow=True, startangle=200, explode=[0.01,0])\n",
        "plt.legend(labels=['Insured','Not insured'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 54% customer are previously insured ahe 46% customer are are not insured yet.\n",
        "* Customer who are not perviosly insured are likely to be inetrested."
      ],
      "metadata": {
        "id": "gXI2bLCyW5qJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "plt.figure(figsize=(15,9))\n",
        "a=df['Annual_Premium']\n",
        "sns.distplot(a, color='purple')"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* From the distribution plot we can infer that the annual premimum variable is right skewed"
      ],
      "metadata": {
        "id": "uCmHaGwTXAWk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.boxplot(df['Annual_Premium'])"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  For the boxplot above we can see that there's a lot of outliers in the annual premium."
      ],
      "metadata": {
        "id": "1OqlJX0gXIjD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "plt.figure(figsize=(5,7))\n",
        "sns.countplot(x=df['Vehicle_Damage'])"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Customers with Vehicle_Damage are likely to buy insurance\n"
      ],
      "metadata": {
        "id": "wimF8E2tXRuw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "df['Vehicle_Age'].hist();"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* From the above plot we can see that most of the people are having vehicle age between 1 or 2 years and very few people are having vehicle age more than 2 years."
      ],
      "metadata": {
        "id": "nA9t6ktMXV0A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "#Age VS Response\n",
        "plt.figure(figsize=(16,8))\n",
        "sns.countplot(data=df, x='Age',hue='Response', palette='CMRmap_r')\n",
        "plt.xlabel('Age response')\n",
        "plt.ylabel('count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* People ages between from 31 to 50 are more likely to respond.\n",
        "*  while Young people below 30 are not interested in vehicle insurance.\n"
      ],
      "metadata": {
        "id": "BwRlQS00XiEc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "#Gender vs Response\n",
        "df.groupby(['Gender', 'Response']).size().unstack().plot(kind = 'bar', stacked = True)"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Male category is slightly greater than that of female and chances of buying the insurance is also little high"
      ],
      "metadata": {
        "id": "szUy0hQAXq0d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code\n",
        "plt.figure(figsize = (10,6) )\n",
        "sns.countplot(data = df, x = 'Vehicle_Age', hue = 'Response', palette='Dark2_r')\n",
        "plt.xlabel('Vehicle Age', fontsize = 15)\n",
        "plt.ylabel('Count', fontsize = 15)\n",
        "plt.title('Vehicle Age and Customer Response analysis', fontsize = 19)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Customers with vechicle age 1-2 years are more likely to interested as compared to the other two\n",
        "\n",
        "* Customers with with Vehicle_Age <1 years have very less chance of buying Insurance"
      ],
      "metadata": {
        "id": "4vMb8XC3X2jW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code\n",
        "sns.barplot(x = 'Response', y ='Annual_Premium', data = df)"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  People who response have slightly higher annual premium"
      ],
      "metadata": {
        "id": "Zy0n6bFuYAuP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 12 visualization\n",
        "plt.figure(figsize = (20, 8))\n",
        "sns.heatmap(df.corr(), annot = True)"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Target variable is not much affected by Vintage variable. we can drop least correlated variable."
      ],
      "metadata": {
        "id": "OEZbpqRPYJJa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Dimensionality reduction."
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X=df.drop(columns=['id','Driving_License','Policy_Sales_Channel','Vintage','Response'])# independent variable\n",
        "y = df['Response']# dependent variable"
      ],
      "metadata": {
        "id": "zrpEyFa3fpxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Missing Values"
      ],
      "metadata": {
        "id": "3do5Io6kfz-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "# Filling any numerical NaNs with mode()\n",
        "\n",
        "fill_mode = lambda col: col.fillna(col.mode())\n",
        "X = X.apply(fill_mode, axis=0)\n",
        "df = df.apply(fill_mode, axis=0)"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. resampling\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FxuAsuQvZXDm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Resampling\n",
        "ros = RandomOverSampler(random_state=0)\n",
        "X_new,y_new= ros.fit_resample(X, y)\n",
        "\n",
        "print(\"After Random Over Sampling Of Minor Class Total Samples are :\", len(y_new))\n",
        "print('Original dataset shape {}'.format(Counter(y)))\n",
        "print('Resampled dataset shape {}'.format(Counter(y_new)))"
      ],
      "metadata": {
        "id": "D_CD7XoFZuV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Splitting the data in train and test sets\n",
        "\n"
      ],
      "metadata": {
        "id": "8bzGwKnzZ15S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test ,y_train, y_test=  train_test_split(X_new, y_new, random_state=42, test_size=0.3)\n",
        "X_train.shape, X_test.shape , y_train.shape, y_test.shape"
      ],
      "metadata": {
        "id": "PJfC-wGMZ0zW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Scaling the data"
      ],
      "metadata": {
        "id": "rly1RfDFZ_rV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing the Dataset using Standard Scaling Technique.\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler=StandardScaler()\n",
        "X_train=scaler.fit_transform(X_train)\n",
        "X_test=scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "SD4Tu7w4aRYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check for imbalance in data\n",
        "df['Response'].value_counts()"
      ],
      "metadata": {
        "id": "0fFXm_mDZJHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "+* We can clearly see that there is a huge difference between the data set.\n",
        "* Standard ML techniques such as Decision Tree and Logistic Regression have a bias towards the majority class, and they tend to ignore the minority class. So solving this issue we use resampling technique.\n"
      ],
      "metadata": {
        "id": "HfzTkRAjZMNb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1 - Logistic regression"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing Logistic Regression\n",
        "model= LogisticRegression(random_state=42)\n",
        "model=model.fit(X_train, y_train)\n",
        "\n",
        "#Making prediction\n",
        "pred = model.predict(X_test)\n",
        "prob = model.predict_proba(X_test)[:,1]"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "r_lgt= recall_score(y_test, pred)\n",
        "print(\"recall_score : \", r_lgt)\n",
        "\n",
        "p_lgt= precision_score(y_test, pred)\n",
        "print(\"precision_score :\",p_lgt)\n",
        "\n",
        "f1_lgt= f1_score(y_test, pred)\n",
        "print(\"f1_score :\", f1_lgt)\n",
        "\n",
        "A_lgt= accuracy_score(pred, y_test)\n",
        "print(\"accuracy_score :\",A_lgt)\n",
        "\n",
        "acu_lgt = roc_auc_score(pred, y_test)\n",
        "print(\"ROC_AUC Score:\",acu_lgt)"
      ],
      "metadata": {
        "id": "3GS6csYOabqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "fpr, tpr, _ = roc_curve(y_test, prob)\n",
        "\n",
        "plt.title('Logistic Regression ROC curve')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.plot(fpr,tpr)\n",
        "plt.plot((0,1), linestyle=\"--\",color='black')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-vc4kg5bafAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# confusion matrix"
      ],
      "metadata": {
        "id": "CRiAulsTamd9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "matrix= confusion_matrix(y_test, pred)\n",
        "print(matrix)\n",
        "sns.heatmap(matrix ,annot=True, fmt='g')"
      ],
      "metadata": {
        "id": "Kl1vhnqHaqY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* From the confusion matrix we see that the model is predicting positive responses but also predicting negative response too."
      ],
      "metadata": {
        "id": "LjfiSnEtaxFD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(pred, y_test))"
      ],
      "metadata": {
        "id": "o5ih8veDa2yZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2 - Ramdom forest classifier"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RF_model= RandomForestClassifier()\n",
        "RF_model= RF_model.fit(X_train, y_train)\n",
        "#Making prediction\n",
        "rf_pred= RF_model.predict(X_test)\n",
        "rf_proba= RF_model.predict_proba(X_test)[:,1]\n",
        "\n",
        "\n",
        "# Evaluation\n",
        "r_rf=  recall_score(y_test, rf_pred)\n",
        "print(\"recall_score : \", r_rf)\n",
        "\n",
        "p_rf= precision_score(y_test, rf_pred)\n",
        "print(\"precision_score :\",p_rf)\n",
        "\n",
        "f1_rf= f1_score(y_test, rf_pred)\n",
        "print(\"f1_score :\", f1_rf)\n",
        "\n",
        "A_rf= accuracy_score(y_test, rf_pred)\n",
        "print(\"accuracy_score :\",A_rf)\n",
        "\n",
        "acu_rf = roc_auc_score(rf_pred, y_test)\n",
        "print(\"ROC_AUC Score:\",acu_rf)"
      ],
      "metadata": {
        "id": "F9JCo8cIa8p5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fpr, tpr, _ = roc_curve(y_test, rf_proba)\n",
        "\n",
        "plt.title('Random Forest ROC curve')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.plot(fpr,tpr)\n",
        "plt.plot((0,1), linestyle=\"--\",color='black')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mpeqo_tqbQJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "confusion matrix"
      ],
      "metadata": {
        "id": "nkZBmGQrbldP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "matrix= confusion_matrix(y_test,rf_pred)\n",
        "print(matrix)\n",
        "sns.heatmap(matrix ,annot=True, fmt='g')"
      ],
      "metadata": {
        "id": "K8AsOOBGbmOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The confusion matrix now shows that the model now is much better with predicting positive responses.\n",
        "\n"
      ],
      "metadata": {
        "id": "DogqEMZJbtpv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(rf_pred, y_test))"
      ],
      "metadata": {
        "id": "kQBYt5kebvJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model performs very well, so we can use it to predict unknown data.\n"
      ],
      "metadata": {
        "id": "WEFvmvM7b11R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "XG_model= XGBClassifier()\n",
        "XG_model= XG_model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "#Making prediction\n",
        "XG_pred = XG_model.predict(X_test)\n",
        "XG_prob = XG_model.predict_proba(X_test)[:,1]"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "r_XG= recall_score(y_test, XG_pred)\n",
        "print(\"recall_score : \", r_XG)\n",
        "\n",
        "p_XG= precision_score(y_test, XG_pred)\n",
        "print(\"precision_score :\",p_XG)\n",
        "\n",
        "f1_XG= f1_score(y_test, XG_pred)\n",
        "print(\"f1_score :\", f1_XG)\n",
        "\n",
        "A_XG= accuracy_score( y_test, XG_pred)\n",
        "print(\"accuracy_score :\",A_XG)\n",
        "\n",
        "acu_XG = roc_auc_score(XG_pred, y_test)\n",
        "print(\"ROC_AUC Score:\",acu_XG)"
      ],
      "metadata": {
        "id": "gtuCFlXeb9Cz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fpr, tpr, _ = roc_curve(y_test, XG_prob)\n",
        "\n",
        "plt.title('XGBoost ROC curve')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.plot(fpr,tpr)\n",
        "plt.plot((0,1), linestyle=\"--\",color='black')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sEw2HZuVcB4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "confusion matrix"
      ],
      "metadata": {
        "id": "DLEohws_cHYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "matrix= confusion_matrix(y_test,XG_pred)\n",
        "print(matrix)\n",
        "sns.heatmap(matrix ,annot=True, fmt='g')"
      ],
      "metadata": {
        "id": "yNB2xpTQcKfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the confusion matrix we see that the model is a bit better with predicting positive responses."
      ],
      "metadata": {
        "id": "V6OOHiDwcRMf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(XG_pred, y_test))"
      ],
      "metadata": {
        "id": "I_oimGrZcMEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Comparing  the Model\n",
        "\n"
      ],
      "metadata": {
        "id": "E4O-qorlcYx_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "com= ['Logistic Regression','Randomforest','XGBClassifier']\n",
        "data={'Accuracy':[A_lgt,A_rf,A_XG],'Recall':[r_lgt,r_rf, r_XG],'Precision':[p_lgt, p_rf, p_XG], 'f1_score':[f1_lgt, f1_rf, f1_XG],'ROC_AUC':[acu_lgt, acu_rf, acu_XG]}\n",
        "result=pd.DataFrame(data=data, index=com)\n",
        "result"
      ],
      "metadata": {
        "id": "1DKbAsXPcWFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Starting from loading our dataset, we initially checked for null values and duplicates. There were no null values and duplicates so treatment of such was not required.\n",
        "* Through Exploratory Data Analysis,we observed that customers belonging to youngAge are more interested in vehicle response.while Young people below 30 are not interested in vehicle insurance. We observed that customers having vehicles older than 2 years are more likely to be interested in vehicle insurance. Similarly, customers having damaged vehicles are more likely to be interested in vehicle insurance.\n",
        "* The variable such as Age, Previously_insured,Annual_premium are more afecting the target variable.\n",
        "* For Feature Selection, we applied the Mutual Information technique. Here we observed that Previously_Insured is the most important feature and has the highest impact on the dependent feature and there is no correlation between the two.\n",
        "* We observed that the target variable was highly imbalanced.So this issue was solved by using Random Over Sample resampling technique.\n",
        "* we applied feature scaling techniques to normalize our data to bring all features on the same scale and make it easier to process by ML algorithms.\n",
        "* Further, we applied Machine Learning Algorithms to determine whether a customer would be interested in Vehicle Insurance.For the logistic regression we got an accuracy of 78% and for the XGBClassifier we got the aacuracy of 79% whereas,.We are getting the highest accuracy of about 91% and ROC_AUC score of 92% with random forest So, From this we can conclude that random forest is the best models as compare to the other models.  "
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}